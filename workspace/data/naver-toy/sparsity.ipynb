{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import scipy.sparse as super\n",
    "import scipy.sparse as sp\n",
    "import random\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "train_path = \"./train.txt\"\n",
    "test_path = \"./test.txt\"\n",
    "n_users = 0\n",
    "n_items = 0\n",
    "n_entities = 0\n",
    "n_relations = 0\n",
    "n_nodes = 0\n",
    "train_user_set = defaultdict(list)\n",
    "test_user_set = defaultdict(list)\n",
    "user_attribute = list()\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0],\n",
       "       [    0,     1],\n",
       "       [    0,     3],\n",
       "       ...,\n",
       "       [13495,  7282],\n",
       "       [13496,  7283],\n",
       "       [13497,  7284]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_cf(file_name):\n",
    "    inter_mat = list()\n",
    "    lines = open(file_name, \"r\").readlines()\n",
    "    for l in lines:\n",
    "        tmps = l.strip()\n",
    "        inters = [int(i) for i in tmps.split(\" \")]\n",
    "\n",
    "        u_id, pos_ids = inters[0], inters[1:]\n",
    "        pos_ids = list(set(pos_ids))\n",
    "        for i_id in pos_ids:\n",
    "            inter_mat.append([u_id, i_id])\n",
    "\n",
    "    return np.array(inter_mat)\n",
    "\n",
    "train_cf = read_cf(train_path)\n",
    "test_cf = read_cf(test_path)\n",
    "train_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_item(train_data, test_data):\n",
    "    global n_users, n_items\n",
    "    n_users = max(max(train_data[:, 0]), max(test_data[:, 0])) + 1\n",
    "    n_items = max(max(train_data[:, 1]), max(test_data[:, 1])) + 1\n",
    "\n",
    "    for u_id, i_id in train_data:\n",
    "        train_user_set[int(u_id)].append(int(i_id))\n",
    "    for u_id, i_id in test_data:\n",
    "        test_user_set[int(u_id)].append(int(i_id))\n",
    "\n",
    "remap_item(train_cf, test_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_triplets(file_name):\n",
    "    global n_entities, n_relations, n_nodes\n",
    "\n",
    "    can_triplets_np = np.loadtxt(file_name, dtype=np.int32)\n",
    "    can_triplets_np = np.unique(can_triplets_np, axis=0)\n",
    "\n",
    "    if True:\n",
    "        # get triplets with inverse direction like <entity, is-aspect-of, item>\n",
    "        inv_triplets_np = can_triplets_np.copy()\n",
    "        inv_triplets_np[:, 0] = can_triplets_np[:, 2]\n",
    "        inv_triplets_np[:, 2] = can_triplets_np[:, 0]\n",
    "        inv_triplets_np[:, 1] = can_triplets_np[:, 1] + max(can_triplets_np[:, 1]) + 1\n",
    "        # consider two additional relations --- 'interact' and 'be interacted'\n",
    "        can_triplets_np[:, 1] = can_triplets_np[:, 1] + 1\n",
    "        inv_triplets_np[:, 1] = inv_triplets_np[:, 1] + 1\n",
    "        # get full version of knowledge graph\n",
    "        triplets = np.concatenate((can_triplets_np, inv_triplets_np), axis=0)\n",
    "    else:\n",
    "        # consider two additional relations --- 'interact'.\n",
    "        can_triplets_np[:, 1] = can_triplets_np[:, 1] + 1\n",
    "        triplets = can_triplets_np.copy()\n",
    "\n",
    "    n_entities = max(max(triplets[:, 0]), max(triplets[:, 2])) + 1  # including items + users\n",
    "    n_nodes = n_entities + n_users\n",
    "    n_relations = max(triplets[:, 1]) + 1\n",
    "\n",
    "\n",
    "    return triplets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = read_triplets(\"./kg_final.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_graph(train_data, triplets):\n",
    "    ckg_graph = nx.MultiDiGraph()\n",
    "    rd = defaultdict(list)\n",
    "\n",
    "    print(\"Begin to load interaction triples ...\")\n",
    "    for u_id, i_id in tqdm(train_data, ascii=True):\n",
    "        rd[0].append([u_id, i_id])\n",
    "\n",
    "    print(\"\\nBegin to load knowledge graph triples ...\")\n",
    "    for h_id, r_id, t_id in tqdm(triplets, ascii=True):\n",
    "        ckg_graph.add_edge(h_id, t_id, key=r_id)\n",
    "        rd[r_id].append([h_id, t_id])\n",
    "\n",
    "    return ckg_graph, rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to load interaction triples ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 68659/68659 [00:00<00:00, 462891.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin to load knowledge graph triples ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 43710/43710 [00:00<00:00, 208267.67it/s]\n"
     ]
    }
   ],
   "source": [
    "graph, relation_dict = build_graph(train_cf, triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_relational_graph(relation_dict):\n",
    "    def _bi_norm_lap(adj):\n",
    "        # D^{-1/2}AD^{-1/2}\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "\n",
    "        d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "        # bi_lap = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt)\n",
    "        bi_lap = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)\n",
    "        return bi_lap.tocoo()\n",
    "\n",
    "    def _si_norm_lap(adj):\n",
    "        # D^{-1}A\n",
    "        rowsum = np.array(adj.sum(1))\n",
    "\n",
    "        d_inv = np.power(rowsum, -1).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.\n",
    "        d_mat_inv = sp.diags(d_inv)\n",
    "\n",
    "        norm_adj = d_mat_inv.dot(adj)\n",
    "        return norm_adj.tocoo()\n",
    "\n",
    "    adj_mat_list = []\n",
    "    print(\"Begin to build sparse relation matrix ...\")\n",
    "    for r_id in tqdm(relation_dict.keys()):\n",
    "        np_mat = np.array(relation_dict[r_id])\n",
    "        if r_id == 0:\n",
    "            cf = np_mat.copy()\n",
    "            cf[:, 1] = cf[:, 1] + n_users  # [0, n_items) -> [n_users, n_users+n_items)\n",
    "            vals = [1.] * len(cf)\n",
    "            adj = sp.coo_matrix((vals, (cf[:, 0], cf[:, 1])), shape=(n_nodes, n_nodes))\n",
    "        else:\n",
    "            vals = [1.] * len(np_mat)\n",
    "            adj = sp.coo_matrix((vals, (np_mat[:, 0], np_mat[:, 1])), shape=(n_nodes, n_nodes))\n",
    "        adj_mat_list.append(adj)\n",
    "\n",
    "    norm_mat_list = [_bi_norm_lap(mat) for mat in adj_mat_list]\n",
    "    mean_mat_list = [_si_norm_lap(mat) for mat in adj_mat_list]\n",
    "    # interaction: user->item, [n_users, n_entities]\n",
    "    norm_mat_list[0] = norm_mat_list[0].tocsr()[:n_users, n_users:].tocoo()\n",
    "    mean_mat_list[0] = mean_mat_list[0].tocsr()[:n_users, n_users:].tocoo()\n",
    "\n",
    "    return adj_mat_list, norm_mat_list, mean_mat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to build sparse relation matrix ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 102.92it/s]\n",
      "/home/kimheesu/anaconda3/envs/tf2.5/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in power\n",
      "  \n",
      "/home/kimheesu/anaconda3/envs/tf2.5/lib/python3.7/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in power\n"
     ]
    }
   ],
   "source": [
    "adj_mat_list, norm_mat_list, mean_mat_list = build_sparse_relational_graph(relation_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kimheesu/anaconda3/envs/tf2.5/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180594101/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "coo = adj_mat_list[0].tocoo()\n",
    "i = torch.LongTensor([coo.row, coo.col])\n",
    "v = torch.from_numpy(coo.data).float()\n",
    "sparse_tensor = torch.sparse.FloatTensor(i,v,coo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = adj_mat_list[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015799815184113237"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity = coo.data.shape[0] / (sparse_matrix.shape[0] * sparse_matrix.shape[1])\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bdffd226db74f32b1e67dcb50a117797eaf84ad68693423287fabc603b29d02"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tf2.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for test in [1,2,4,5]:\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from data_loader import load_data\n",
    "import logging\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.dataset=\"naver-toy\"\n",
    "args.dim=16\n",
    "args.n_hop=2\n",
    "args.kge_weight=0.01\n",
    "args.l2_weight=1e-7\n",
    "args.lr=0.02\n",
    "args.batch_size=1024\n",
    "args.n_epoch=1\n",
    "args.n_memory=32\n",
    "args.item_update_mode=\"plus_transform\"\n",
    "args.using_all_hops=True\n",
    "args.use_cuda = True\n",
    "args.show_topk =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading rating file ...\n",
      "splitting dataset ...\n",
      "reading KG file ...\n",
      "constructing knowledge graph ...\n",
      "constructing ripple set ...\n"
     ]
    }
   ],
   "source": [
    "data_info = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_loss=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_file = \"../data/\"+args.dataset+\"/ratings_final\"\n",
    "rating_np = np.load(rating_file+\".npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 65497,  41347, 138471, ...,   7107, 136362, 109953])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "n_ratings = rating_np.shape[0]\n",
    "eval_indices = np.random.choice(n_ratings, size=int(n_ratings*eval_ratio),replace=False)\n",
    "eval_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = set(range(n_ratings))- set(eval_indices)\n",
    "test_indices = np.random.choice(list(left), size=int(n_ratings*test_ratio), replace=False)\n",
    "train_indices = list(left - set(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_dict = dict()\n",
    "for i in train_indices[:]:\n",
    "    user = rating_np[i][0]\n",
    "    item = rating_np[i][1]\n",
    "    rating = rating_np[i][2]\n",
    "    if rating == 1:\n",
    "        if user not in user_history_dict:\n",
    "            user_history_dict[user] = []\n",
    "        user_history_dict[user].append(item)\n",
    "train_indices2 = [i for i in train_indices if rating_np[i][0] in user_history_dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95776"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95776"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = rating_np[train_indices]\n",
    "eval_data = rating_np[eval_indices]\n",
    "test_data = rating_np[test_indices]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31925"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31925"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159626"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data) + len(eval_data)+len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13341"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_set = set()\n",
    "for data in train_data:\n",
    "    user_idx = data[0]\n",
    "    train_user_set.add(user_idx)\n",
    "len(train_user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95056"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = rating_np[train_indices2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95056"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "class RippleNet(nn.Module):\n",
    "    def __init__(self, args, n_entity, n_relation):\n",
    "        super(RippleNet, self).__init__()\n",
    "\n",
    "        self._parse_args(args, n_entity, n_relation)\n",
    "\n",
    "        self.entity_emb = nn.Embedding(self.n_entity, self.dim)\n",
    "        self.relation_emb = nn.Embedding(self.n_relation, self.dim * self.dim)\n",
    "        self.transform_matrix = nn.Linear(self.dim, self.dim, bias=False)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def _parse_args(self, args, n_entity, n_relation):\n",
    "        self.n_entity = n_entity\n",
    "        self.n_relation = n_relation\n",
    "        self.dim = args.dim\n",
    "        self.n_hop = args.n_hop\n",
    "        self.kge_weight = args.kge_weight\n",
    "        self.l2_weight = args.l2_weight\n",
    "        self.lr = args.lr\n",
    "        self.n_memory = args.n_memory\n",
    "        self.item_update_mode = args.item_update_mode\n",
    "        self.using_all_hops = args.using_all_hops\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        items: torch.LongTensor,\n",
    "        labels: torch.LongTensor,\n",
    "        memories_h: list,\n",
    "        memories_r: list,\n",
    "        memories_t: list,\n",
    "    ):\n",
    "        # [batch size, dim]\n",
    "        item_embeddings = self.entity_emb(items)\n",
    "        h_emb_list = []\n",
    "        r_emb_list = []\n",
    "        t_emb_list = []\n",
    "        for i in range(self.n_hop):\n",
    "            # [batch size, n_memory, dim]\n",
    "            h_emb_list.append(self.entity_emb(memories_h[i]))\n",
    "            # [batch size, n_memory, dim, dim]\n",
    "            r_emb_list.append(\n",
    "                self.relation_emb(memories_r[i]).view(\n",
    "                    -1, self.n_memory, self.dim, self.dim\n",
    "                )\n",
    "            )\n",
    "            # [batch size, n_memory, dim]\n",
    "            t_emb_list.append(self.entity_emb(memories_t[i]))\n",
    "\n",
    "        o_list, item_embeddings = self._key_addressing(\n",
    "            h_emb_list, r_emb_list, t_emb_list, item_embeddings\n",
    "        )\n",
    "        scores = self.predict(item_embeddings, o_list)\n",
    "\n",
    "        return_dict = self._compute_loss(\n",
    "            scores, labels, h_emb_list, t_emb_list, r_emb_list\n",
    "        )\n",
    "        return_dict[\"scores\"] = scores\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    def _compute_loss(self, scores, labels, h_emb_list, t_emb_list, r_emb_list):\n",
    "        base_loss = self.criterion(scores, labels.float())\n",
    "\n",
    "        kge_loss = 0\n",
    "        for hop in range(self.n_hop):\n",
    "            # [batch size, n_memory, 1, dim]\n",
    "            h_expanded = torch.unsqueeze(h_emb_list[hop], dim=2)\n",
    "            # [batch size, n_memory, dim, 1]\n",
    "            t_expanded = torch.unsqueeze(t_emb_list[hop], dim=3)\n",
    "            # [batch size, n_memory, dim, dim]\n",
    "            hRt = torch.squeeze(\n",
    "                torch.matmul(torch.matmul(h_expanded, r_emb_list[hop]), t_expanded)\n",
    "            )\n",
    "            kge_loss += torch.sigmoid(hRt).mean()\n",
    "        kge_loss = -self.kge_weight * kge_loss\n",
    "\n",
    "        l2_loss = 0\n",
    "        for hop in range(self.n_hop):\n",
    "            l2_loss += (h_emb_list[hop] * h_emb_list[hop]).sum()\n",
    "            l2_loss += (t_emb_list[hop] * t_emb_list[hop]).sum()\n",
    "            l2_loss += (r_emb_list[hop] * r_emb_list[hop]).sum()\n",
    "        l2_loss = self.l2_weight * l2_loss\n",
    "\n",
    "        loss = base_loss + kge_loss + l2_loss\n",
    "        return dict(base_loss=base_loss, kge_loss=kge_loss, l2_loss=l2_loss, loss=loss)\n",
    "\n",
    "    def _key_addressing(self, h_emb_list, r_emb_list, t_emb_list, item_embeddings):\n",
    "        o_list = []\n",
    "        for hop in range(self.n_hop):\n",
    "            # [batch_size, n_memory, dim, 1]\n",
    "            h_expanded = torch.unsqueeze(h_emb_list[hop], dim=3)\n",
    "\n",
    "            # [batch_size, n_memory, dim]\n",
    "            Rh = torch.squeeze(torch.matmul(r_emb_list[hop], h_expanded))\n",
    "\n",
    "            # [batch_size, dim, 1]\n",
    "            v = torch.unsqueeze(item_embeddings, dim=2)\n",
    "\n",
    "            # [batch_size, n_memory]\n",
    "            probs = torch.squeeze(torch.matmul(Rh, v))\n",
    "\n",
    "            # [batch_size, n_memory]\n",
    "            probs_normalized = F.softmax(probs, dim=1)\n",
    "\n",
    "            # [batch_size, n_memory, 1]\n",
    "            probs_expanded = torch.unsqueeze(probs_normalized, dim=2)\n",
    "\n",
    "            # [batch_size, dim]\n",
    "            o = (t_emb_list[hop] * probs_expanded).sum(dim=1)\n",
    "\n",
    "            item_embeddings = self._update_item_embedding(item_embeddings, o)\n",
    "            o_list.append(o)\n",
    "        return o_list, item_embeddings\n",
    "\n",
    "    def _update_item_embedding(self, item_embeddings, o):\n",
    "        if self.item_update_mode == \"replace\":\n",
    "            item_embeddings = o\n",
    "        elif self.item_update_mode == \"plus\":\n",
    "            item_embeddings = item_embeddings + o\n",
    "        elif self.item_update_mode == \"replace_transform\":\n",
    "            item_embeddings = self.transform_matrix(o)\n",
    "        elif self.item_update_mode == \"plus_transform\":\n",
    "            item_embeddings = self.transform_matrix(item_embeddings + o)\n",
    "        else:\n",
    "            raise Exception(\"Unknown item updating mode: \" + self.item_update_mode)\n",
    "        return item_embeddings\n",
    "\n",
    "    def predict(self, item_embeddings, o_list):\n",
    "        y = o_list[-1]\n",
    "        if self.using_all_hops:\n",
    "            for i in range(self.n_hop - 1):\n",
    "                y += o_list[i]\n",
    "\n",
    "        # [batch_size]\n",
    "        scores = (item_embeddings * y).sum(dim=1)\n",
    "        return torch.sigmoid(scores)\n",
    "\n",
    "    def evaluate(self, items, labels, memories_h, memories_r, memories_t):\n",
    "        return_dict = self.forward(items, labels, memories_h, memories_r, memories_t)\n",
    "        scores = return_dict[\"scores\"].detach().cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        auc = roc_auc_score(y_true=labels, y_score=scores)\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "        acc = np.mean(np.equal(predictions, labels))\n",
    "        return auc, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ctr_eval(args, model, data, ripple_set, batch_size):\n",
    "    auc_list = []\n",
    "    f1_list = []\n",
    "    model.eval()\n",
    "    start = 0\n",
    "    while start < data.shape[0]:\n",
    "        labels = data[start:start + args.batch_size, 2]\n",
    "        return_dict = model(*get_feed_dict(args, model, data, ripple_set, start, start + batch_size))\n",
    "        scores = return_dict[\"scores\"]\n",
    "        scores = scores.detach().cpu().numpy()\n",
    "        auc = roc_auc_score(y_true=labels, y_score=scores)\n",
    "        predictions = [1 if i >= 0.5 else 0 for i in scores]\n",
    "        f1 = f1_score(y_true=labels, y_pred=predictions)\n",
    "        auc_list.append(auc)\n",
    "        f1_list.append(f1)\n",
    "        start += args.batch_size\n",
    "    model.train()  \n",
    "    auc = float(np.mean(auc_list))\n",
    "    f1 = float(np.mean(f1_list))\n",
    "    return auc, f1\n",
    "\n",
    "\n",
    "def topk_eval(args, model, train_data, test_data, ripple_set):\n",
    "    # logging.info('calculating recall ...')\n",
    "    k_list = [5, 10, 20, 50, 100]\n",
    "    recall_list = {k: [] for k in k_list}\n",
    "\n",
    "    item_set = set(train_data[:,1].tolist() + test_data[:,1].tolist())\n",
    "    train_record = _get_user_record(args, train_data, True)\n",
    "    test_record = _get_user_record(args, test_data, False)\n",
    "    user_list = list(set(train_record.keys()) & set(test_record.keys()))\n",
    "    user_num = 13498\n",
    "    if len(user_list) > user_num:\n",
    "        np.random.seed()    \n",
    "        user_list = np.random.choice(user_list, size=user_num, replace=False)\n",
    "    data = np.vstack([train_data, test_data])\n",
    "    print(\"len(user_list): \", len(user_list))\n",
    "    # model.eval()\n",
    "    # for user in user_list:\n",
    "    #     test_item_list = list(item_set-set(train_record[user]))\n",
    "    #     item_score_map = dict()\n",
    "    #     start = 0\n",
    "    #     while start + args.batch_size <= len(test_item_list):\n",
    "    #         items = test_item_list[start:start + args.batch_size] \n",
    "    #         # input_data = _get_topk_feed_data(user, items)\n",
    "    #         return_dict = model(*get_feed_dict(args, model, data, ripple_set, start, start + args.batch_size))\n",
    "    #         scores = return_dict[\"scores\"]\n",
    "    #         for item, score in zip(items, scores):\n",
    "    #             item_score_map[item] = score\n",
    "    #         start += args.batch_size\n",
    "    #     # padding the last incomplete mini-batch if exists\n",
    "    #     if start < len(test_item_list):\n",
    "    #         res_items = test_item_list[start:] + [test_item_list[-1]] * (args.batch_size - len(test_item_list) + start)\n",
    "    #         # input_data = _get_topk_feed_data(user, res_items)\n",
    "    #         return_dict = model(*get_feed_dict(args, model, data, ripple_set, start, start + args.batch_size))\n",
    "    #         scores = return_dict[\"scores\"]\n",
    "    #         for item, score in zip(res_items, scores):\n",
    "    #             item_score_map[item] = score\n",
    "    #     item_score_pair_sorted = sorted(item_score_map.items(), key=lambda x: x[1], reverse=True)\n",
    "    #     item_sorted = [i[0] for i in item_score_pair_sorted]\n",
    "    #     for k in k_list:\n",
    "    #         hit_num = len(set(item_sorted[:k]) & set(test_record[user]))\n",
    "    #         recall_list[k].append(hit_num / len(set(test_record[user])))\n",
    "    # model.train()  \n",
    "    # recall = [np.mean(recall_list[k]) for k in k_list]\n",
    "    # _show_recall_info(zip(k_list, recall))\n",
    "    # return recall\n",
    "\n",
    "    \n",
    "def _init_model(args, data_info):\n",
    "    n_entity = data_info[3]\n",
    "    n_relation = data_info[4]\n",
    "    model = RippleNet(args, n_entity, n_relation)\n",
    "    if args.use_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr = args.lr,\n",
    "        weight_decay = args.l2_weight,\n",
    "    )\n",
    "    loss_func = nn.BCELoss()\n",
    "    return model, optimizer, loss_func\n",
    "    \n",
    "    \n",
    "def _get_feed_data(args, data, user_triple_set, item_triple_set, start, end):\n",
    "    # origin item\n",
    "    items = torch.LongTensor(data[start:end, 1])\n",
    "    if args.use_cuda:\n",
    "        items = items.cuda()\n",
    "    # kg propagation embeddings\n",
    "    users_triple = _get_triple_tensor(args, data[start:end,0], user_triple_set)\n",
    "    items_triple = _get_triple_tensor(args, data[start:end,1], item_triple_set)\n",
    "    return items, users_triple, items_triple\n",
    "\n",
    "\n",
    "def _get_feed_label(args,labels):\n",
    "    labels = torch.FloatTensor(labels)\n",
    "    if args.use_cuda:\n",
    "        labels = labels.cuda()\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _get_triple_tensor(args, objs, triple_set):\n",
    "    # [h,r,t]  h: [layers, batch_size, triple_set_size]\n",
    "    h,r,t = [], [], []\n",
    "    for i in range(args.n_layer):\n",
    "        h.append(torch.LongTensor([triple_set[obj][i][0] for obj in objs]))\n",
    "        r.append(torch.LongTensor([triple_set[obj][i][1] for obj in objs]))\n",
    "        t.append(torch.LongTensor([triple_set[obj][i][2] for obj in objs]))\n",
    "        if args.use_cuda:\n",
    "            h = list(map(lambda x: x.cuda(), h))\n",
    "            r = list(map(lambda x: x.cuda(), r))\n",
    "            t = list(map(lambda x: x.cuda(), t))\n",
    "    return [h,r,t]\n",
    "\n",
    "\n",
    "def _get_user_record(args, data, is_train):\n",
    "    user_history_dict = dict()\n",
    "    for rating in data:\n",
    "        user = rating[0]\n",
    "        item = rating[1]\n",
    "        label = rating[2]\n",
    "        if is_train or label == 1:\n",
    "            if user not in user_history_dict:\n",
    "                user_history_dict[user] = set()\n",
    "            user_history_dict[user].add(item)\n",
    "    return user_history_dict\n",
    "\n",
    "\n",
    "def _get_topk_feed_data(user, items):\n",
    "    res = list()\n",
    "    for item in items:\n",
    "        res.append([user,item])\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "def _show_recall_info(recall_zip):\n",
    "    res = \"\"\n",
    "    for i,j in recall_zip:\n",
    "        res += \"K@%d:%.4f  \"%(i,j)\n",
    "    logging.info(res)\n",
    "\n",
    "def get_feed_dict(args, model, data, ripple_set, start, end):\n",
    "    items = torch.LongTensor(data[start:end, 1])\n",
    "    labels = torch.LongTensor(data[start:end, 2])\n",
    "    memories_h, memories_r, memories_t = [], [], []\n",
    "    for i in range(args.n_hop):\n",
    "        memories_h.append(torch.LongTensor([ripple_set[user][i][0] for user in data[start:end, 0]]))\n",
    "        memories_r.append(torch.LongTensor([ripple_set[user][i][1] for user in data[start:end, 0]]))\n",
    "        memories_t.append(torch.LongTensor([ripple_set[user][i][2] for user in data[start:end, 0]]))\n",
    "    if args.use_cuda:\n",
    "        items = items.cuda()\n",
    "        labels = labels.cuda()\n",
    "        memories_h = list(map(lambda x: x.cuda(), memories_h))\n",
    "        memories_r = list(map(lambda x: x.cuda(), memories_r))\n",
    "        memories_t = list(map(lambda x: x.cuda(), memories_t))\n",
    "    return items, labels, memories_h, memories_r,memories_t\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_info[0]\n",
    "eval_data = data_info[1]\n",
    "test_data = data_info[2]\n",
    "\n",
    "train_record = _get_user_record(args, train_data, True)\n",
    "test_record = _get_user_record(args, test_data, False)\n",
    "eval_record = _get_user_record(args, eval_data,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95044"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12855"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_set = set()\n",
    "for data in train_data:\n",
    "    user_idx = data[0]\n",
    "    train_user_set.add(user_idx)\n",
    "len(train_user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12855"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = set(train_record.keys()) | set(test_record.keys()) | set(eval_record.keys())\n",
    "len(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12855"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_record.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '9', '1'],\n",
       " ['0', '10', '1'],\n",
       " ['0', '3', '1'],\n",
       " ['0', '12', '1'],\n",
       " ['0', '8', '1']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/naver-toy/ratings_final.txt\", \"r\") as f:\n",
    "    ratings_final = f.readlines()\n",
    "\n",
    "ratings_final = [rating.replace(\"\\n\",\"\") for rating in ratings_final]\n",
    "ratings_final = [rating.split(\"\\t\") for rating in ratings_final]\n",
    "ratings_final[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13498"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_set = set()\n",
    "for rating in ratings_final:\n",
    "    user_idx = rating[0]\n",
    "    user_set.add(int(user_idx))\n",
    "len(user_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159626"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{42,\n",
       " 101,\n",
       " 265,\n",
       " 634,\n",
       " 646,\n",
       " 727,\n",
       " 767,\n",
       " 848,\n",
       " 851,\n",
       " 857,\n",
       " 886,\n",
       " 894,\n",
       " 899,\n",
       " 917,\n",
       " 921,\n",
       " 951,\n",
       " 973,\n",
       " 987,\n",
       " 1003,\n",
       " 1019,\n",
       " 1045,\n",
       " 1055,\n",
       " 1179,\n",
       " 1204,\n",
       " 1270,\n",
       " 1297,\n",
       " 1306,\n",
       " 1345,\n",
       " 1435,\n",
       " 1438,\n",
       " 1481,\n",
       " 1569,\n",
       " 1591,\n",
       " 1611,\n",
       " 1621,\n",
       " 1625,\n",
       " 1653,\n",
       " 1657,\n",
       " 1663,\n",
       " 1664,\n",
       " 1665,\n",
       " 1887,\n",
       " 1966,\n",
       " 1972,\n",
       " 1978,\n",
       " 2108,\n",
       " 2111,\n",
       " 2127,\n",
       " 2141,\n",
       " 2147,\n",
       " 2153,\n",
       " 2154,\n",
       " 2176,\n",
       " 2184,\n",
       " 2296,\n",
       " 2339,\n",
       " 2468,\n",
       " 2477,\n",
       " 2527,\n",
       " 2529,\n",
       " 2570,\n",
       " 2602,\n",
       " 2631,\n",
       " 2872,\n",
       " 2882,\n",
       " 2886,\n",
       " 2905,\n",
       " 3057,\n",
       " 3094,\n",
       " 3100,\n",
       " 3107,\n",
       " 3109,\n",
       " 3115,\n",
       " 3122,\n",
       " 3154,\n",
       " 3199,\n",
       " 3213,\n",
       " 3218,\n",
       " 3304,\n",
       " 3468,\n",
       " 3552,\n",
       " 3598,\n",
       " 3671,\n",
       " 3735,\n",
       " 3744,\n",
       " 3835,\n",
       " 3848,\n",
       " 3939,\n",
       " 4189,\n",
       " 4199,\n",
       " 4202,\n",
       " 4216,\n",
       " 4248,\n",
       " 4275,\n",
       " 4304,\n",
       " 4419,\n",
       " 4429,\n",
       " 4503,\n",
       " 4504,\n",
       " 4590,\n",
       " 4653,\n",
       " 4663,\n",
       " 4665,\n",
       " 4706,\n",
       " 4853,\n",
       " 4905,\n",
       " 4936,\n",
       " 4946,\n",
       " 4972,\n",
       " 4975,\n",
       " 5097,\n",
       " 5188,\n",
       " 5191,\n",
       " 5217,\n",
       " 5232,\n",
       " 5251,\n",
       " 5265,\n",
       " 5298,\n",
       " 5399,\n",
       " 5400,\n",
       " 5444,\n",
       " 5464,\n",
       " 5499,\n",
       " 5502,\n",
       " 5519,\n",
       " 5524,\n",
       " 5532,\n",
       " 5550,\n",
       " 5555,\n",
       " 5571,\n",
       " 5602,\n",
       " 5676,\n",
       " 5718,\n",
       " 5750,\n",
       " 6029,\n",
       " 6037,\n",
       " 6040,\n",
       " 6071,\n",
       " 6082,\n",
       " 6103,\n",
       " 6277,\n",
       " 6332,\n",
       " 6335,\n",
       " 6338,\n",
       " 6357,\n",
       " 6375,\n",
       " 6388,\n",
       " 6389,\n",
       " 6398,\n",
       " 6399,\n",
       " 6414,\n",
       " 6444,\n",
       " 6523,\n",
       " 6525,\n",
       " 6550,\n",
       " 6566,\n",
       " 6611,\n",
       " 6637,\n",
       " 6692,\n",
       " 6710,\n",
       " 6784,\n",
       " 6894,\n",
       " 6939,\n",
       " 6940,\n",
       " 6943,\n",
       " 6944,\n",
       " 6951,\n",
       " 6954,\n",
       " 6960,\n",
       " 7017,\n",
       " 7047,\n",
       " 7071,\n",
       " 7190,\n",
       " 7336,\n",
       " 7390,\n",
       " 7396,\n",
       " 7416,\n",
       " 7418,\n",
       " 7434,\n",
       " 7441,\n",
       " 7480,\n",
       " 7504,\n",
       " 7556,\n",
       " 7564,\n",
       " 7565,\n",
       " 7678,\n",
       " 7708,\n",
       " 7711,\n",
       " 7722,\n",
       " 7730,\n",
       " 7734,\n",
       " 7736,\n",
       " 7737,\n",
       " 7742,\n",
       " 7743,\n",
       " 7747,\n",
       " 7751,\n",
       " 7780,\n",
       " 7800,\n",
       " 7814,\n",
       " 7840,\n",
       " 7847,\n",
       " 7872,\n",
       " 7995,\n",
       " 7997,\n",
       " 8036,\n",
       " 8059,\n",
       " 8156,\n",
       " 8305,\n",
       " 8355,\n",
       " 8364,\n",
       " 8414,\n",
       " 8420,\n",
       " 8442,\n",
       " 8482,\n",
       " 8555,\n",
       " 8569,\n",
       " 8592,\n",
       " 8624,\n",
       " 8646,\n",
       " 8685,\n",
       " 8687,\n",
       " 8688,\n",
       " 8729,\n",
       " 8777,\n",
       " 8787,\n",
       " 8798,\n",
       " 8831,\n",
       " 8832,\n",
       " 8909,\n",
       " 8971,\n",
       " 8977,\n",
       " 9016,\n",
       " 9109,\n",
       " 9115,\n",
       " 9132,\n",
       " 9158,\n",
       " 9170,\n",
       " 9174,\n",
       " 9248,\n",
       " 9284,\n",
       " 9291,\n",
       " 9300,\n",
       " 9316,\n",
       " 9332,\n",
       " 9354,\n",
       " 9361,\n",
       " 9377,\n",
       " 9395,\n",
       " 9397,\n",
       " 9398,\n",
       " 9439,\n",
       " 9508,\n",
       " 9548,\n",
       " 9605,\n",
       " 9639,\n",
       " 9659,\n",
       " 9671,\n",
       " 9690,\n",
       " 9779,\n",
       " 9796,\n",
       " 9807,\n",
       " 9815,\n",
       " 9821,\n",
       " 9858,\n",
       " 9887,\n",
       " 9890,\n",
       " 9899,\n",
       " 9952,\n",
       " 9983,\n",
       " 10007,\n",
       " 10046,\n",
       " 10050,\n",
       " 10056,\n",
       " 10059,\n",
       " 10066,\n",
       " 10230,\n",
       " 10235,\n",
       " 10306,\n",
       " 10351,\n",
       " 10356,\n",
       " 10394,\n",
       " 10488,\n",
       " 10497,\n",
       " 10503,\n",
       " 10562,\n",
       " 10572,\n",
       " 10574,\n",
       " 10652,\n",
       " 10664,\n",
       " 10665,\n",
       " 10680,\n",
       " 10700,\n",
       " 10713,\n",
       " 10716,\n",
       " 10721,\n",
       " 10724,\n",
       " 10729,\n",
       " 10739,\n",
       " 10744,\n",
       " 10746,\n",
       " 10748,\n",
       " 10750,\n",
       " 10752,\n",
       " 10753,\n",
       " 10765,\n",
       " 10795,\n",
       " 10806,\n",
       " 10847,\n",
       " 10853,\n",
       " 10857,\n",
       " 10870,\n",
       " 10872,\n",
       " 10973,\n",
       " 10977,\n",
       " 10981,\n",
       " 10982,\n",
       " 10984,\n",
       " 10989,\n",
       " 10998,\n",
       " 10999,\n",
       " 11014,\n",
       " 11016,\n",
       " 11030,\n",
       " 11080,\n",
       " 11083,\n",
       " 11098,\n",
       " 11115,\n",
       " 11117,\n",
       " 11144,\n",
       " 11167,\n",
       " 11170,\n",
       " 11187,\n",
       " 11192,\n",
       " 11229,\n",
       " 11237,\n",
       " 11244,\n",
       " 11282,\n",
       " 11309,\n",
       " 11376,\n",
       " 11401,\n",
       " 11410,\n",
       " 11426,\n",
       " 11519,\n",
       " 11531,\n",
       " 11547,\n",
       " 11550,\n",
       " 11552,\n",
       " 11553,\n",
       " 11554,\n",
       " 11555,\n",
       " 11564,\n",
       " 11637,\n",
       " 11638,\n",
       " 11640,\n",
       " 11648,\n",
       " 11658,\n",
       " 11659,\n",
       " 11662,\n",
       " 11663,\n",
       " 11671,\n",
       " 11675,\n",
       " 11679,\n",
       " 11687,\n",
       " 11693,\n",
       " 11742,\n",
       " 11743,\n",
       " 11784,\n",
       " 11796,\n",
       " 11797,\n",
       " 11836,\n",
       " 11839,\n",
       " 11874,\n",
       " 11877,\n",
       " 11878,\n",
       " 11925,\n",
       " 11961,\n",
       " 11974,\n",
       " 12014,\n",
       " 12015,\n",
       " 12018,\n",
       " 12019,\n",
       " 12026,\n",
       " 12028,\n",
       " 12029,\n",
       " 12034,\n",
       " 12042,\n",
       " 12047,\n",
       " 12048,\n",
       " 12054,\n",
       " 12055,\n",
       " 12108,\n",
       " 12117,\n",
       " 12118,\n",
       " 12170,\n",
       " 12171,\n",
       " 12225,\n",
       " 12228,\n",
       " 12230,\n",
       " 12231,\n",
       " 12233,\n",
       " 12237,\n",
       " 12241,\n",
       " 12243,\n",
       " 12250,\n",
       " 12251,\n",
       " 12255,\n",
       " 12263,\n",
       " 12300,\n",
       " 12301,\n",
       " 12309,\n",
       " 12312,\n",
       " 12314,\n",
       " 12317,\n",
       " 12321,\n",
       " 12322,\n",
       " 12323,\n",
       " 12325,\n",
       " 12333,\n",
       " 12342,\n",
       " 12344,\n",
       " 12348,\n",
       " 12380,\n",
       " 12399,\n",
       " 12407,\n",
       " 12408,\n",
       " 12418,\n",
       " 12426,\n",
       " 12440,\n",
       " 12443,\n",
       " 12444,\n",
       " 12457,\n",
       " 12466,\n",
       " 12486,\n",
       " 12513,\n",
       " 12521,\n",
       " 12535,\n",
       " 12540,\n",
       " 12541,\n",
       " 12544,\n",
       " 12548,\n",
       " 12549,\n",
       " 12550,\n",
       " 12552,\n",
       " 12555,\n",
       " 12558,\n",
       " 12562,\n",
       " 12567,\n",
       " 12570,\n",
       " 12571,\n",
       " 12573,\n",
       " 12603,\n",
       " 12636,\n",
       " 12639,\n",
       " 12641,\n",
       " 12649,\n",
       " 12655,\n",
       " 12658,\n",
       " 12659,\n",
       " 12661,\n",
       " 12671,\n",
       " 12685,\n",
       " 12686,\n",
       " 12696,\n",
       " 12698,\n",
       " 12701,\n",
       " 12702,\n",
       " 12767,\n",
       " 12778,\n",
       " 12782,\n",
       " 12783,\n",
       " 12796,\n",
       " 12797,\n",
       " 12800,\n",
       " 12803,\n",
       " 12840,\n",
       " 12841,\n",
       " 12842,\n",
       " 12871,\n",
       " 12878,\n",
       " 12890,\n",
       " 12904,\n",
       " 12906,\n",
       " 12912,\n",
       " 12914,\n",
       " 12918,\n",
       " 12922,\n",
       " 12923,\n",
       " 12925,\n",
       " 12927,\n",
       " 12928,\n",
       " 12931,\n",
       " 12933,\n",
       " 12934,\n",
       " 12935,\n",
       " 12936,\n",
       " 12937,\n",
       " 12940,\n",
       " 12942,\n",
       " 12943,\n",
       " 12950,\n",
       " 12951,\n",
       " 12952,\n",
       " 12953,\n",
       " 12954,\n",
       " 12957,\n",
       " 12959,\n",
       " 12971,\n",
       " 12978,\n",
       " 12986,\n",
       " 12987,\n",
       " 12988,\n",
       " 12997,\n",
       " 12998,\n",
       " 13000,\n",
       " 13004,\n",
       " 13008,\n",
       " 13016,\n",
       " 13032,\n",
       " 13033,\n",
       " 13036,\n",
       " 13041,\n",
       " 13046,\n",
       " 13062,\n",
       " 13066,\n",
       " 13068,\n",
       " 13079,\n",
       " 13081,\n",
       " 13082,\n",
       " 13084,\n",
       " 13091,\n",
       " 13095,\n",
       " 13097,\n",
       " 13099,\n",
       " 13101,\n",
       " 13108,\n",
       " 13110,\n",
       " 13122,\n",
       " 13126,\n",
       " 13129,\n",
       " 13133,\n",
       " 13136,\n",
       " 13149,\n",
       " 13159,\n",
       " 13160,\n",
       " 13166,\n",
       " 13177,\n",
       " 13178,\n",
       " 13184,\n",
       " 13185,\n",
       " 13192,\n",
       " 13198,\n",
       " 13199,\n",
       " 13201,\n",
       " 13208,\n",
       " 13214,\n",
       " 13216,\n",
       " 13218,\n",
       " 13219,\n",
       " 13222,\n",
       " 13228,\n",
       " 13229,\n",
       " 13230,\n",
       " 13231,\n",
       " 13234,\n",
       " 13242,\n",
       " 13245,\n",
       " 13246,\n",
       " 13248,\n",
       " 13254,\n",
       " 13257,\n",
       " 13262,\n",
       " 13263,\n",
       " 13269,\n",
       " 13276,\n",
       " 13281,\n",
       " 13282,\n",
       " 13284,\n",
       " 13285,\n",
       " 13286,\n",
       " 13295,\n",
       " 13297,\n",
       " 13301,\n",
       " 13313,\n",
       " 13315,\n",
       " 13321,\n",
       " 13322,\n",
       " 13324,\n",
       " 13329,\n",
       " 13330,\n",
       " 13331,\n",
       " 13332,\n",
       " 13335,\n",
       " 13338,\n",
       " 13342,\n",
       " 13347,\n",
       " 13349,\n",
       " 13354,\n",
       " 13356,\n",
       " 13358,\n",
       " 13360,\n",
       " 13364,\n",
       " 13375,\n",
       " 13377,\n",
       " 13384,\n",
       " 13386,\n",
       " 13393,\n",
       " 13394,\n",
       " 13396,\n",
       " 13398,\n",
       " 13401,\n",
       " 13406,\n",
       " 13408,\n",
       " 13409,\n",
       " 13410,\n",
       " 13413,\n",
       " 13414,\n",
       " 13415,\n",
       " 13419,\n",
       " 13421,\n",
       " 13425,\n",
       " 13432,\n",
       " 13434,\n",
       " 13435,\n",
       " 13444,\n",
       " 13445,\n",
       " 13446,\n",
       " 13448,\n",
       " 13449,\n",
       " 13457,\n",
       " 13462,\n",
       " 13465,\n",
       " 13467,\n",
       " 13468,\n",
       " 13469,\n",
       " 13480,\n",
       " 13481,\n",
       " 13485,\n",
       " 13486,\n",
       " 13491,\n",
       " 13492,\n",
       " 13495,\n",
       " 13496}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_set.difference(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"[%(asctime)s] %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "\n",
    "def train(args, data_info, show_loss):\n",
    "    # logging.info(\"================== training CKAN ====================\")\n",
    "    train_data = data_info[0]\n",
    "    eval_data = data_info[1]\n",
    "    test_data = data_info[2]\n",
    "    n_entity = data_info[3]\n",
    "    n_relation = data_info[4]\n",
    "    ripple_set = data_info[5]\n",
    "    # model, optimizer, loss_func = _init_model(args, data_info)\n",
    "    model = RippleNet(args, n_entity, n_relation)\n",
    "    if args.use_cuda:\n",
    "        model.cuda()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p : p.requires_grad, model.parameters()), args.lr\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    for step in range(10):\n",
    "        np.random.shuffle(train_data)\n",
    "        start = 0\n",
    "        while start < train_data.shape[0]:\n",
    "            return_dict = model(*get_feed_dict(args, model, train_data, ripple_set, start, start + args.batch_size))\n",
    "            loss = return_dict[\"loss\"]\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            start += args.batch_size\n",
    "        eval_auc, eval_f1 = ctr_eval(args, model, eval_data, ripple_set, args.batch_size)\n",
    "        test_auc, test_f1 = ctr_eval(args, model, test_data, ripple_set, args.batch_size)\n",
    "        ctr_info = 'epoch %.2d    eval auc: %.4f f1: %.4f    test auc: %.4f f1: %.4f'\n",
    "        logging.info(ctr_info, step, eval_auc, eval_f1, test_auc, test_f1)\n",
    "        if args.show_topk:\n",
    "            topk_eval(args, model, train_data, test_data, ripple_set)\n",
    "        #     # recall = topk_eval(args, model, train_data, test_data, user_triple_set, item_triple_set)\n",
    "        #     # print(f\"recall : {recall}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:36,095] INFO: epoch 00    eval auc: 0.5036 f1: 0.3761    test auc: 0.4946 f1: 0.3677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:39,406] INFO: epoch 01    eval auc: 0.5133 f1: 0.2496    test auc: 0.5089 f1: 0.2384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:42,751] INFO: epoch 02    eval auc: 0.5303 f1: 0.2633    test auc: 0.5254 f1: 0.2551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:46,015] INFO: epoch 03    eval auc: 0.5446 f1: 0.2977    test auc: 0.5401 f1: 0.2923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:49,338] INFO: epoch 04    eval auc: 0.5501 f1: 0.3022    test auc: 0.5480 f1: 0.2933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:52,630] INFO: epoch 05    eval auc: 0.5667 f1: 0.2885    test auc: 0.5632 f1: 0.2849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:56,012] INFO: epoch 06    eval auc: 0.5811 f1: 0.3146    test auc: 0.5752 f1: 0.3068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:51:59,355] INFO: epoch 07    eval auc: 0.5872 f1: 0.3383    test auc: 0.5806 f1: 0.3313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:52:02,750] INFO: epoch 08    eval auc: 0.5976 f1: 0.3521    test auc: 0.5898 f1: 0.3434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-30 14:52:06,109] INFO: epoch 09    eval auc: 0.6035 f1: 0.3759    test auc: 0.5967 f1: 0.3696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(user_list):  8538\n"
     ]
    }
   ],
   "source": [
    "train(args, data_info, show_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bdffd226db74f32b1e67dcb50a117797eaf84ad68693423287fabc603b29d02"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('tf2.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
